---
title: 'Establishing determinant importance using CIBER: an introduction and tutorial'
author: "Gjalt-Jorn Peters & Rik Crutzen"
date: "`r format(Sys.time(), '%H:%M:%S on %Y-%m-%d %Z (GMT%z)')`"
output:
  html_document:
    df_print: paged
---

<!--   This is the R Markdown file for the article "Establishing     -->
<!--   determinant importance using CIBER: an introduction and       -->
<!--   tutorial" by Crutzen and Peters, 2018. Scroll down for the    -->
<!--   article text, and further down for the analyses.              -->

```{r setup, include=FALSE}
#############################################################################
### Packages
#############################################################################

if (!require('userfriendlyscience', quietly = FALSE)) {
  stop("You need to have the userfriendlyscience package installed!");
}
safeRequire('scales');    ### For rescale
safeRequire('dplyr');     ### For case_when
safeRequire('ppcor');     ### To compute partial and semipartial correlations
safeRequire('eulerr');    ### Venn-Euler diagrams
safeRequire('viridis');   ### Colors
safeRequire('gridExtra'); ### Combining plots
safeRequire('grid');      ### Drawing plots
safeRequire('ggplot2');   ### Saving plots

########################################################################
### Settings
########################################################################

knitr::opts_chunk$set(echo=FALSE,
                      cache=FALSE,
                      comment=NA,
                      rows.print=40);

options(width = 160);
options(xtable.type = "html");
options(ufs.debug = FALSE);

```

```{r regsCovarPlot}

regsCovarPlot <- function(formula, data, circle=FALSE, silent=TRUE) {
  varNames <- all.vars(formula);
  if (length(varNames) != 3) {
    stop("This function only works for exactly three variables (one ",
         "criterion (or dependent variable) and two predictors). You ",
         "supplied ", length(varNames), ".");
  }
  dat <- data[, varNames];
  dat <- dat[complete.cases(dat), ];
  yName <- varNames[1];
  x1Name <- varNames[2];
  x2Name <- varNames[3];
  dat[, yName] <- scale(dat[, yName]);
  dat[, x1Name] <- scale(dat[, x1Name]);
  dat[, x2Name] <- scale(dat[, x2Name]);
  cors <- cor(dat);
  pcors <- pcor(dat)$estimate;
  spcors <- spcor(dat)$estimate;
  
  lmForY <- lm(as.formula(paste0(yName, "~", x1Name, "+", x2Name)),
               data=dat);
  
  Rsq.y.x1x2 <-
    summary(lmForY)$r.squared;
  Rsq.x1.x2y <-
    summary(lm(as.formula(paste0(x1Name, "~", x2Name, "+", yName)),
               data=dat))$r.squared;
  Rsq.x2.x1y <-
    summary(lm(as.formula(paste0(x2Name, "~", x1Name, "+", yName)),
               data=dat))$r.squared;

  Rsq.y.x1 <-
    cors[yName, x1Name]^2;
  Rsq.y.x2 <-
    cors[yName, x2Name]^2;
  Rsq.x1.x2 <-
    cors[x1Name, x2Name]^2;

  y.unique <- 1 - Rsq.y.x1x2;
  x1.unique <- 1- Rsq.x1.x2y;
  x2.unique <- 1- Rsq.x2.x1y;
  
  x1y <- Rsq.y.x1x2 - Rsq.y.x2;
  x2y <- Rsq.y.x1x2 - Rsq.y.x1;
  
  x1x2y.fromX1 <- Rsq.y.x1 - x1y;
  x1x2y.fromX2 <- Rsq.y.x2 - x2y;
  
  if (!silent) {
    if (x1x2y.fromX1 != x1x2y.fromX2) {
      cat0("There is a minor difference between x1x2y overlap estimated from x1y (", x1x2y.fromX1,
           ") and from x2y (", x1x2y.fromX2, "). The size of this difference is ",
           x1x2y.fromX2 - x1x2y.fromX1, ".\n\n");
    }
  }
  
  x1x2y <- x1x2y.fromX1;
  
  x1x2 <- Rsq.x1.x2 - x1x2y;

  coefx1 <- coef(lmForY)[2];
  coefx2 <- coef(lmForY)[3];
    
  inputVector <- c("Y" = round(y.unique, 3),
                   "X1" = round(x1.unique, 3),
                   "X2" = round(x2.unique, 3),
                   "Y&X1&X2" = round(x1x2y, 3),
                   "Y&X1" = round(x1y, 3),
                   "Y&X2" = round(x2y, 3),
                   "X1&X2" = round(x1x2, 3));
  
  names(inputVector) <- c(yName,
                          x1Name,
                          x2Name,
                          paste(yName, x1Name, x2Name, sep="&"),
                          paste(yName, x1Name, sep="&"),
                          paste(yName, x2Name, sep="&"),
                          paste(x1Name, x2Name, sep="&"));
  
  eulerDiagram.ellipse <- euler(inputVector,
                                shape='ellipse');
  eulerDiagram.circle <- euler(inputVector,
                               shape='circle');
  
  if (!silent) {
    print(cors);
    cat("\n");
    cat0("Unique variance in ", yName, ": ", round(y.unique, 3), "\n");
    cat0("Unique variance in ", x1Name, ": ", round(x1.unique, 3), "\n");
    cat0("Unique variance in ", x2Name, ": ", round(x2.unique, 3), "\n");
    cat0("R^2 for ", yName, " from ", x1Name, " & ", x2Name, ": ", round(Rsq.y.x1x2, 3), "\n");
    cat0("R^2 for ", x1Name, " from ", x2Name, " & ", yName, ": ", round(Rsq.x1.x2y, 3), "\n");
    cat0("R^2 for ", x2Name, " from ", x1Name, " & ", yName, ": ", round(Rsq.x2.x1y, 3), "\n");
    cat0("Overlap ", x1Name, " and ", x2Name, " and ", yName, ": ", inputVector[4], "\n");
    cat0("Overlap ", x1Name, " and ", yName, ": ", inputVector[5], "\n");
    cat0("Overlap ", x2Name, " and ", yName, ": ", inputVector[6], "\n");
    cat0("Overlap ", x1Name, " and ", x2Name, ": ", inputVector[7], "\n");
    cat0("Regression coefficient for ", x1Name, ": ", round(coefx1, 3), " (squared: ", round(coefx1^2, 3), ")\n");
    cat0("Regression coefficient for ", x2Name, ": ", round(coefx2, 3), " (squared: ", round(coefx2^2, 3), ")\n");
  }
  
  if (circle) {
    if (!silent) {
      cat0("\nCircle:\n");
      print(eulerDiagram.circle);
    }
    return(plot(eulerDiagram.circle,
                           quantities=TRUE,
                           fill=viridis,
                           alpha = .2));
  } else {
    if (!silent) {
      cat0("\nEllipse:\n");
      print(eulerDiagram.ellipse);
    }
    return(plot(eulerDiagram.ellipse,
                           quantities=TRUE,
                           fill=viridis,
                           alpha = .2));
  }
  
}

```

```{r questionnaire}

questionnaire <-
  matrix(c("Intention", "I intend to submit my next manuscript to Health Psychology Bulletin.", "Absolutely not", "Absolutely",
           "Intention", "I will submit my next manuscript to Health Psychology Bulletin.", "Unlikely", "Likely",
           "Intention", "I am willing to submit my next manuscript to Health Psychology Bulletin.", "False", "True",
           "Intention", "I plan to submit my next manuscript to Health Psychology Bulletin.", "Absolutely not", "Absolutely",
           "Attitude", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Bad", "Good",
           "Attitude", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Unpleasant", "Pleasant",
           "Attitude", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Harmful", "Beneficial",
           "Attitude", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Boring", "Interesting",
           "Importance", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Unimportant", "Important",
           "Importance", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Not essential", "Essential",
           "Importance", "For me, submitting my next manuscript tip Health Psychology Bulletin is ...", "Not significant", "Significant",
           "Self-identity", "I see myself as someone who is concerned about submitting my next manuscript to Health Psychology Bulletin.", "Not at all", "Completely",
           "Self-identity", "I see myself as someone who submits their next manuscript to Health Psychology Bulletin.", "Not at all", "Completely",
           "Self-identity", "I would feel at a loss if I were forced to give up submitting my next manuscript to Health Psychology Bulletin.", "Absolutely not", "Absolutely",
           "Self-identity", "Submitting my next manuscript to Health Psychology Bulletin is an important part of who I am.", "Not at all", "Very much so",
           "Self-identity", "I am the kind of person who submits their next manuscript to Health Psychology Bulletin.", "Not at all", "Completely",
           "Self-identity", "For me, submitting my next manuscript to Health Psychology Bulletin means more than just the act itself.", "Not at all", "Very much so",
           "Self-identity", "Submitting my next manuscript to Health Psychology Bulletin is something I rarely even think about.", "Not at all", "Very much so"),
         byrow=TRUE,
         ncol=4);

questionnaire <- as.data.frame(questionnaire);
names(questionnaire) <- c("Variable", "Item", "Left anchor", "Right anchor");

```

```{r create-dataset, message=FALSE, warning=FALSE}

sampleSize <- 200;

### Simluate a dataset with the latent variables

invisible(capture.output(latentDat <-
  simDataSet(sampleSize,
             varNames = c('intention',
                          'attitude',
                          'importance',
                          'selfIdentity'),
             specifiedCorrelations = list(c('intention', 'attitude', .6),
                                          c('intention', 'importance', .6),
                                          c('intention', 'selfIdentity', .6),
                                          c('attitude', 'importance', .7),
                                          c('attitude', 'selfIdentity', .5),
                                          c('importance', 'selfIdentity', .7)),
             ranges=NULL,
             seed = 20180721,
             empirical=FALSE,
             silent=TRUE)));

### Create items by adding unreliability to each indicator

dat <- data.frame('intention_intend' = latentDat$intention + rnorm(sampleSize, 0, 1),
                  'intention_will' = latentDat$intention + rnorm(sampleSize, 0, 1),
                  'intention_willing' = latentDat$intention + rnorm(sampleSize, 0, 1),
                  'intention_plan' = latentDat$intention + rnorm(sampleSize, 0, 1),
                  'attitude_good' = latentDat$attitude + rnorm(sampleSize, 0, 1),
                  'attitude_pleasant' = latentDat$attitude + rnorm(sampleSize, 0, 1),
                  'attitude_beneficial' = latentDat$attitude + rnorm(sampleSize, 0, 1),
                  'attitude_interesting' = latentDat$attitude + rnorm(sampleSize, 0, 1),
                  'importance_important' = latentDat$importance + rnorm(sampleSize, 0, 1),
                  'importance_essential' = latentDat$importance + rnorm(sampleSize, 0, 1),
                  'importance_significant' = latentDat$importance + rnorm(sampleSize, 0, 1),
                  'selfIdentity_concernedAbout' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1),
                  'selfIdentity_considerMyself' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1),
                  'selfIdendity_feelAtALoss' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1),
                  'selfIdentify_importantPart' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1),
                  'selfIdentify_kindOfPerson' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1),
                  'selfIdentify_meansMoreThan' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1),
                  'selfIdentity_rarelyEvenThinkAbout' = latentDat$selfIdentity + rnorm(sampleSize, 0, 1));

### Recale items to 1-5 response scale; first we rescale to 0-6;
### then we round all numbers; then we collapse 0 and 1, and 5 and 6.
dat <- as.data.frame(apply(dat, 2, function(x) {
  ### Set parameters determining item's distribution
  lower <- 0;
  upper <- 6;
  shift <- 0;
  ### Rescale, shift, round, and fit into 1-5 scale
  x <- scales::rescale(x, to=c(lower, upper));
  x <- x + shift;
  x <- round(x);
  x <- dplyr::case_when(x < 1 ~ 1,
                        x > 5 ~ 5,
                        TRUE ~ x);
  }));

### For convenience, make lists with the item names
scaleNames <- names(latentDat);
intentionItems <- grep('intention_\\w+', names(dat), value=TRUE);
attitudeItems <- grep('attitude_\\w+', names(dat), value=TRUE);
importanceItems <- grep('importance_\\w+', names(dat), value=TRUE);
selfIdentityItems <- grep('selfIdentity_\\w+', names(dat), value=TRUE);

### Check scale structure
# scaleStructure(dat, items=intentionItems);
# scaleStructure(dat, items=attitudeItems);
# scaleStructure(dat, items=importanceItems);
# scaleStructure(dat, items=selfIdentityItems);

### Compute scales
dat <- makeScales(dat,
                  list(intention = intentionItems,
                       attitude = attitudeItems,
                       importance = importanceItems,
                       selfIdentity = selfIdentityItems,
                       attitudeImportance = c(attitudeItems,
                                              importanceItems),
                       selfIdentityImportance = c(selfIdentityItems,
                                                  importanceItems)));

### Standardizing the variables
dat[, scaleNames] <- lapply(dat[, scaleNames],
                            scale);

```

# Manuscript text

When developing behavior change interventions, it is important to target the most important determinants of behavior. This is challenging for two reasons. First, determinant selection requires integrating multiple information sources: determinants' associations to behavior or determinants mediating an effect on behavior (i.e. effect sizes), as well as how much room for improvement there is in the population (i.e. means and spread). Second, only information from samples is normally available, which means that point estimates will vary from sample to sample. In practice, determinant studies often present multivariate regression analyses, but this is problematic because by default, shared covariance is removed from the equation (literally), compromising operationalisations' validity and affecting effect sizes (i.e., the results of such analyses cannot be used as a first source of information regarding each determinant's association to behavior).

In the present contribution, we will briefly explain these points in more detail, after which we will introduce a solution: confidence interval based estimation of relevance (CIBER). We will then present a brief tutorial as to how to generate CIBER plots and how to interpret them.

## Why determinant importance is important

Public health interventions have to potential to be cost-effective means to improve health and well-being. They often do this by targeting human behavior. All overt human behavior is controlled from neurons in the motor cortex, activation of which occurs through activation of other neural networks. Therefore, any successful behavior change intervention necessarily achieves this success by changing aspects of the human psychology that are important for the target behavior.

Successfully changing aspects of human psychology requires learning in the target individuals. Humans have evolved several learning processes which, if properly leveraged, may realise this learning. These evolutionary learning principles correspond to types of memory, and therefore, different evolutionary learning principles may be used to target different types of aspects of the human psychology. Because these evolutionary learning principles operate at a very fundamental level of human psychology, psychologists studying behavior change have studied behavior change principles on higher levels of abstraction.

Similarly, psychologists have studied the aspects of human psychology that determine whether an individual performs a behavior on relatively high levels of abstraction. Many theories of behavior change propose constructs that predict behavior called determinants. Of these determinants, principles that can be applied to change them have been studied. These principles are called 'methods for behavior change' in the Intervention Mapping protocol for intervention development and analysis, and the various BCT taxonomies, although developed to describe intervention elements regardless of potential effectiveness, may also contain some BCTs that leverage one or more behavior change principles.

Given the richness of human psychology, it is no surprise that there exist no 'magic bullet' behavior change principles that can always be relied on. Instead, which behavior change principles are most likely to be effective depends on which types of memories must be targeted. This link manifests as a pairing of determinants and behavior change principles, such that the likelihood of engaging the underlying evolutionary learning principles is optimal.

As a consequence, a crucial step in the development of behavior change interventions is the selection of the most important determinants. After all, these determinants can be seen as the buttons one needs to push to establish behavior change.

## When a determinant is important

Determinant importance depends on two things. The first is the determinant's association to behavior, or, as is often the case, to a theoretical mediator of the determinant's effect on behavior. For example, when an interventon developer develops an intervention for a reasoned behavior, a suitable theory may be the Reaoned Action Approach. This theory holds that behavior is predicted by a determinant called intention (i.e. a person's intention to engage in the behavior), which in turn is predicted by three other determinants: attitude (a person's evaluation of the behavior's consequences), perceived norms (a person's perception of the approval and behavior of relevant social referents), and perceived behavioral control (a person's perception of their ability and control over the behavior). If a determinant study is conducted and the correlation of attitude to intention and behavior is zero, it seems unlikely that changes in attitude will result in behavior change. However, even if a determinant is strongly associated to behavior or a theoretical mediator, it may still not be a relevant intervention target.

This is because of the second thing that determinant importance depends on: the distribution of the determinants' scores in the population (as estimated by inspecting the distribution of sample scores). A determinant that is strongly associated to behavior may still be a bad choice as intervention target if its distribution is very skewed. For example, most ecstasy users are aware that using a high dose of ecstasy is bad for their health. Even if this variable is strongly associated to their behavior, this association is caused by only a few people who deny these health effects. When developing an intervention, investing resources in targeting this small group will yield less total effects on behavior than when targeting a determinant with a weaker association but with more room for improvement.

Note that this reasoning does not only hold when selecting determinants (such as attitude), but also when selecting subdeterminants. Subdeterminants are here defined as determinants at a lower level of psychological generality that are theoretically assumed to predict or be a part of overarching determinants. This definition means that whether a determinant is called a 'determinant' or a 'subdeterminant' is somewhat arbitrary. For example, within the RAA, attitudinal beliefs such as expectancies or risk perceptions can be called subdeterminants, because they are theoretically assumed to predict, or be a part of, their 'overarching' determinant attitude. At the same time, attitude, perceived norms, and perceived behavioral control can be called subdeterminants because they are theoretically assumed to predict, or be a part of, their 'overarching' determinant intention (note that perceived behavioral control is also assumed to influence behavior directly, so the case could be made that labeling it a subdeterminant would be inaccurate).

So, to summarize, successful behavior change requires successful change of one or more aspects of human psychology. These aspects are defined in, and can be operationalised using, psychological theory, and are called (sub-)determinants. Once operationalised, their importance can be established to identify the best intervention targets. Establishing this (sub-)determinant importance requires simultaneous inspection of the determinant's association to theoretical mediators of its effects on behavior, potentially to behavior directly, and of the determinant's distribution. Most researchers do this by computing point estimates (e.g., correlation coefficients), but unfortunately, these are virtually uninformative on their own.

## Why point estimates cannot be used to estimate determinant importance

When inspecting association and distribution estimates, the population values are always unknown. The only way to learn about a population is by taking a random sample and inspecting that sample. This instrument, however, is somewhat of a mixed blessing. On the one hand, sampling provides the researcher with a way to 'look at' the population. On the other hand, sampling, by its random nature, necessarily introduces random variation. This means that whatever is observed in the sample may not reflect the population.

This creates the somewhat frustrating situation that the only means available to observe a population also inevitably distort that observation. Any value computed from a sample will have a different value if the sampling is repeated. Therefore, the specific estimate arrived at on the basis of any particular sample has next to no value. It is also necessary to know how accurate the estimate is: how much it can be expected to differ between samples. Fortunately, there is a way to estimate this.

This estimation of accuracy is based on the concept of the sampling distribution: the theoretical distribution containing all potential values for any sample estimate, given its (unknown) population value and the sample size. Because the population value is always unknown (otherwise one wouldn't have to sample in the first place), the true sampling distribution is necessarily also known. However, for many parameters that can be estimated from a sample, the shape and spread of the sampling distribution *are* known. This means that the sampling distribution can be constructed for any hypothetical population value.

The best known example is perhaps the sampling distribution of the mean, which is approximately normally distributed (except for extremely small samples) with a standard deviation equal to the population standard deviation divided by the square root of the sample size. Knowing the sampling distribution's distribution shape and spread allow computation of intervals that contain, in infinite repetitions of the sampling procedure, the population value in a given percentage of the samples: the confidence interval. A wide confidence interval means that the point estimate is very unreliable and can have a substantially different value in a new sample, whereas a tight confidence interval means that a substantially different value in a new sample is less likely. These properties, in combination with the fact that health psychologists are generally familiar with confidence intervals, make them well suited for estimation of population values from sample data.

Therefore, whenever using sample data to draw conclusions for intervention development (or anything, really), point estimates should not be used. Instead, also considering estimate accuracy, for example by computing confidence intervals, allows taking the inevitable sampling and error variation into account. However, this also means that inspecting determinant importance becomes almost an inhuman task: one has to simultaneously compare three times as much information. Visualisation can help, and this is what confidence interval based estimation of relevance (CIBER) is based on. CIBER plots simultaneously visualise (sub-)determinant distributions, confidence intervals for the mean, and confidence intervals for bivariate correlations to one or more theoretical mediators and/or behavior. Before explaining how to order and read a CIBER plot, we will explain why CIBER plots use correlations instead of regression coefficients.

## Why regression coefficients cannot be used to estimate determinant importance

Determinant studies often contain regression analyses where a theoretical mediator of determinants' effects, on behavior or behavior itself, is regressed on the measured determinants (or subdeterminants). Such regression analyses are useful, because they yield a multiple correlation coefficient: the correlation of the criterion (dependent variable) with the best prediction of the criterion as computed from the predictors in the model. Squaring this multiple correlation coefficient yields *R<sup>2</sup>*, the proportion of the variance in the criterion that can be explained by the predictors in this sample. Because the distribution of *R<sup>2</sup>* is known, a confidence interval can be constructed, allowing tentative conclusions as to likely population *R<sup>2</sup>* values, which is indicative of the maximum effect that can be expected of an intervention that successfully changes all determinants in the model.

A convenient feature of regression analysis is that overlap between predictors in their explanation of the criterion is removed from the equation (quite literally, in the case of regression). Squaring a correlation coefficient always yields the proportion of explained variance: if attitude and intention have a bivariate (i.e. zero-order) correlation of *r* = `r formatR(cor(dat$intention, dat$attitude))`, that means that they each explain `r formatR(cor(dat$intention, dat$attitude)^2)` of each other's variance in the sample. The 95% confidence interval runs from `r formatCI(regr(dat$intention ~ dat$attitude)$output$rsq.ci)`, which gives some idea of how far the explained variance in the population can be expected to deviate from that sample estimate. Another determinant, self-identity, has a correlation of *r*=`r formatR(cor(dat$intention, dat$selfIdentity))` with intention, and so this determinant explains `r formatR(cor(dat$intention, dat$selfIdentity)^2)` of intention.

However, attitude and self-identity correlate with each other (*r* = `r formatR(cor(dat$attitude, dat$selfIdentity))`). It is therefore likely that they also share explained variance in intention. In that case, simply adding together the proportion of intention's variance they each explain (`r formatR(cor(dat$intention, dat$attitude)^2)` + `r formatR(cor(dat$intention, dat$selfIdentity)^2)` = `r formatR(cor(dat$intention, dat$attitude)^2 + cor(dat$intention, dat$selfIdentity)^2)`) would yield an overestimate of how much intention these determinants explain together (which is in fact `r formatR(regr(dat$intention ~ dat$attitude + dat$selfIdentity)$intermediate$rsq)` in this sample, with a 95% confidence interval of `r formatCI(regr(dat$intention ~ dat$attitude + dat$selfIdentity)$output$rsq.ci)`).

This correction of overlap in explained variance is very useful, and enables better estimation of the variance explained by all predictors together. However, this overlap between predictors is in itself highly problematic when dealing with the regression coefficients of the psychological constructs used as predictors. This problem is the consequence of potential overlap in their operationalisations.

Assuming the applications of the used operationalisations in the relevant sample have high validity (after all, if they have low validity, it makes no sense to analyse the resulting data), correlation between the corresponding data series represents relevant information about human psychology. For example, the two constructs may cover the same aspects of human psychology according to their definition. In that case their operationalisations will also measure the same aspects of human psychology, and therefore, the data series generated by these operationalisations will correlate. Or alternatively, the constructs may be independent but causally related, either because they influence each other (directly or through one or more mediators) or are both influenced by the same third variable. As we argued before, it is hard to empirically distinguish between constructs that influence or consist of each other (Peters & Crutzen, 2017), and the distinction is irrelevant with respect to the problem that surfaces in multivariate analyses.

In this case, removing the variance representing this overlap from the data series corresponding to a construct's operationalisation means removing variance that corresponds to aspects of human psychology that fall within the definition of the construct. In other words, removing this shared variance from a determinant and only considering variance that is not shared with other determinants means that the resulting data series no longer represents the determinant as originally operationalised, and therefore, as defined, but an unknown alteration of this determinant.

This is a necessary consequence of observational research: if two dataseries share explained variance in a third dataseries, it is impossible to know to which dataseries the shared explained variance 'belongs'. In fact, it is likely it belongs to both: if the correlation between the dataseries is indicative of overlap in the definitions of the two constructs that correspond to the data series, these two constructs explain the same aspects of the criterion. Therefore, removing this shared explained variance when estimating the regression coefficients means that these regression coefficients no longer represent the association of each predictor to the criterion. Instead, they represent the association of some unknown part of each predictor with some unknown part of the criterion.

Another way to think about this is by using the formulation often invoked when explaining regression analyses: the regression coefficient expresses the association of a predictor to the criterion *holding all other predictors constant*. If two predictors overlap in their definition, or, in other words, if the definitions of the constructs represented by the two predictors contain the same aspects of human psychology, then 'holding all other predictors constant' means 'neglecting a part of human psychology'. This means the resulting situation is unrealistic and can never occur. Given that the operationalisations of both constructs was valid, this also means that the omitted aspects of human psychology are in fact important to predicting the relevant behavior. Therefore, a predictor that represents an important determinant of behavior may nonetheless have a small regression coefficient, because an important part of the human psychology as defined in the constructs definition was omitted from the coefficient.

Because this can be hard to grasp, we include an example. Imagine we do a mini determinant study. We measure two determinants of intention: attitude and self-identity. Self-identity is one of the variables explicitly covered by Fishbein and Ajzen (2010) in their discussion of potential fourth variables that could be added to the Theory of Planned Behavior (or, by implication, its successor, the Reasoned Action Approach). They argued that the concept was ill-defined, and that common operationalisations actually covered the perceived 'importance' of a behavior. They argued that this can be considered part of the attitude construct, and therefore, including 'importance scale' to attitude's measurement would eliminate any additional explained variance by self-identity. Given that importance can clearly be considered both a part of attitude and self-identity, this lends it well to an illustration of our point.

In this hypothetical determinant study, therefore, we include the importance scale in addition to the determinants (attitude and self-identity) and the criterion (intention). We have included the items used in this hypothetical study in the R Markdown file in the supplementary materials (see the Open Science Framework at https://osf.io/hg4ks/). The correlations used in the earlier illustrations were in fact derived from this hypothetical determinant study. Figure 1 shows two Venn Euler diagrams that use the `eulerr` package (Larsson, 2018) to show the proportional areas of overlap in explained variance between the three variables in this determinant study.

```{r figure-1, fig.width=11, fig.height=5, fig.cap="Venn Euler diagrams showing the overlap in explained variance between attitude, self-identity, and intention. In the diagram on the left, the importance scale is left our of their operationalisation; in the diagram on the right, it is included."}
fig1 <-
  arrangeGrob(regsCovarPlot(intention ~ attitude + selfIdentity,
                            dat),
              regsCovarPlot(intention ~ attitudeImportance + selfIdentityImportance,
                            dat),
              ncol=2);
grid.draw(fig1);
ggsave(fig1,
       filename = "figure1.png",
       width=11, height=5);

```

The left diagram shows the situation where attitude and self-identity are operationalised without including the importance scale. In this sample, the correlation coefficients with intention are `r formatR(cor(dat$intention, dat$attitude))` for attitude and `r formatR(cor(dat$intention, dat$selfIdentity))` for self-identity, they together explain `r formatR(regr(dat$intention ~ dat$attitude + dat$selfIdentity)$intermediate$rsq)` of the variance in intention, and their regression coefficients are respectively `r formatR(regr(dat$intention ~ dat$attitude + dat$selfIdentity)$output$coef.raw['attitude', 'estimate'])` and `r formatR(regr(dat$intention ~ dat$attitude + dat$selfIdentity)$output$coef.raw['selfIdentity', 'estimate'])` (all variables are standardized). As the left diagram shows, the squared correlation between attitude and intention is *r*^2 = .03 + .07 = .10, and the squared correlation between self-identify and intention is *r*^2 = .151 + .07 = .221. In this situation, .07 or seven percent of the covariance between the variables is omitted from the equation when the regression coefficients are estimated.

The right diagram shows the situation where the importance scale is included in the operationalisation of both constructs. In this sample, the correlation coefficients with intention are `r formatR(cor(dat$intention, dat$attitudeImportance))` for attitude and `r formatR(cor(dat$intention, dat$selfIdentityImportance))` for self-identity, they together explain `r formatR(regr(dat$intention ~ dat$attitudeImportance + dat$selfIdentityImportance)$intermediate$rsq)` of the variance in intention, and their regression coefficients are respectively `r formatR(regr(dat$intention ~ dat$attitudeImportance + dat$selfIdentityImportance)$output$coef.raw['attitudeImportance', 'estimate'])` and `r formatR(regr(dat$intention ~ dat$attitudeImportance + dat$selfIdentityImportance)$output$coef.raw['selfIdentityImportance', 'estimate'])`. This diagram shows the large overlap between the variables: .176 of the variance is shared between attitude, self-identity, and intention. This .176 represents almost twenty percent of the variance in intention that cannot be designated to one of the predictors (and therefore, is not reflected in their regression coefficients).

In the left situation, the correlations indicate that both attitude and self-identity seem feasible intervention targets. When removing their overlap, the apparent feasibility of attitude drops a bit, and althought this paints a slightly misleading picture by exagerating the differences in importance between attitude and self-identity, the effect is quite subtle.

However, the right graph paints a different picture. When both predictors represent determinants that are defined, and operationalised, as partly covering the same aspects of human psychology, the difference between correlations and regression coefficients becomes substantial. Whereas the correlation coefficients would again imply that both determinants are feasible intervention targets, based on the regression coefficients, attitude seems irrelevant to predicting intention.

That conclusion, however, would be wrong. It would be valid only if one would redefine attitude such that all overlap with self-identity, in their prediction of intention, is removed from attitude's variance. That would mean the resulting data seties (i.e. the residuals) no longer represent the determinant attitude. After all, that construct's definition did include importance.

It is unclear what exactly the two remaining data series do represent. Psychological constructs often covary, and this covariance represents not bias or measurement error, but real aspects of human psychology. Removing such covariance from estimations of a construct's importance means that it is no longer clear what is being inspected.

This becomes problematic when engaging in behavior change. For example, in this case, the intervention developer may mistakenly decide to only try and target self-identity. While for attitude, a wealth of behavior change methods exists (see Kok et al., 2015 [IM TAXONOMY PAPER]), for self-identity, no effective methods have been identified, and while some may exist, it seems likely that successfully changing self-identity is much harder than successfully changing attitude.

Thus, because estimates from multivariate analyses are problematic when establishing determinant relevance, it is better to base such decisions on the bivariate correlations, or more accurately, on the confidence intervals for these correlation coefficients, together with the information about the (sub-)determinants' distributions and means. We will now illustrate a method for efficiently inspecting all this information simultaneously: confidence interval based estimation of relevance.

## Confidence interval based estimation of relevance

To illustrate confidence interval based estimation of relevance (CIBER), we will use four subdeterminants of attitude as these allow a more complete demonstration. The resulting CIBER plot is shown in Figure 2 (we refer readers who are interested in the CIBER plots obtained from the determinants' association with intention to the OSF repository of this article at https://osf.io/hg4ks/).

```{r figure-2, fig.width=11, fig.height=5, fig.cap="CIBER plots of both situations."}
fig2 <- CIBER(dat,
              determinants=c('attitude_good',
                             'attitude_pleasant',
                             'attitude_beneficial',
                             'attitude_interesting'),
              targets=c('attitude', 'intention'),
              subQuestions=as.character(questionnaire[questionnaire$Variable=='Attitude', 'Item']),
              leftAnchors=as.character(questionnaire[questionnaire$Variable=='Attitude', 'Left anchor']),
              rightAnchors=as.character(questionnaire[questionnaire$Variable=='Attitude', 'Right anchor']));
grid.draw(fig2);
ggsave(fig2,
       filename = "figure2.png",
       width=12, height=3);
```

A CIBER plot contains a large amount of information. First, the left-hand panel shows the questions used to measure these subdeterminants, the left and right anchors of the answer scales, each participants' score, and a 99.99% confidence interval for the mean. This allows easy spotting of skewed distributions or other deviations from normality which are important to take into account when selecting determinants for intervention (with these simulated data, these distributions are approximately normal; for a real-life example, see Crutzen, Peters & Noijen, 2017).

The right-hand panel shows each subdeterminant's association to both attitude and intention. Each correlation coefficient is represented by a diamond showing the point estimate as well as the lower and upper bounds. Because attitude is the mean of the scors on these four items, the correlations of the subdeterminants with attitude are very high, while the correlations with intention are considerably lower.

Finally, the CIBER plot's title shows the proportions of explained variance. This title simultaneously functions as a legend to identfty which diamonds correspond to which determinant. As can be seen here, the proportion of explained variance of attitude could not be estimated; this makes sense, because it is necessarily 1 (after all, attitude is the mean of the four subdeterminants).

To generate a CIBER plot, a function is available in the free R package `userfriendlyscience` (Peters, 2017). To install the package in R, use the following command;

```
install.packages('userfriendlyscience');
```

This command is necessary only once; once the package has been installed, it will remain available. After having installed the package, it can be loaded in an R session by using the following command:

```
require('userfriendlyscience');
```

This needs to be repeated in every R session (because R has thousands of packages available, these are not all automatically loaded every time; users can indicate which packages they need in a session).

Then, the CIBER plot can be generated using the `CIBER` command. For example, a simple version of the CIBER plot shown in Figure 2 can be obtained with this command:

```
CIBER(data=dat,
      determinants=c('attitude_good',
                     'attitude_pleasant',
                     'attitude_beneficial',
                     'attitude_interesting'),
      targets=c('attitude', 'intention'));
```

In this command, the first argument ('data') specifies the data to use; the second argument ('determinants'), the determinants (the rows of the CIBER plot); and the third argument ('targets'), the higher level determinants or behavior variables with which to show associations in the right-hand panel.

It is possible to customize the plot by specifying, as was done in Figure 2, the questions used for each (sub-)determinant by using the 'subQuestions' argument; the left and right anchors by using the 'leftAnchor' and 'rightAnchor' arguments, and it is also possible to change the colors and set other options. An overview of all available options is available by using the following command, which will load the manual page for the CIBER command:

```
?CIBER
```

## Conclusion

Establishing the relative importance of a set of (sub-)determinants, to then select the best intervention targets and be able to select the most fitting behavior change principles (e.g. methods for behavior change or behavior change techniques), is no straightforward affair. This involves a number of pitfalls. In this article, we aimed to describe these pitfall, explain why they are problematic, and we present an easy-to-use solution that is freely available. CIBER plots allow researchers and intervention developers to simultaneously evaluate the large amounts of information that need to be evaluated to select the determinants to target in an intervention to optimize the probability of successful behavior change. We hope this can contribute to more informed determinant selection and ultimately, more effective behavior change interventions.




# Appendix

## Background

Note that because this is a living project, you will probably need the most up-to-date version of the `userfriendlyscience` package (*if* that has been submitted to CRAN yet). See https://userfriendlyscience.com for instructions as to how to install it (or instructions for how to install it from Github).

### Full Disclosure

The Open Science Framework repository for this article is https://osf.io/hg4ks/.

### License of these materials

This file and the other materials in the OSF and GitHub repo's associated with this project are licensed under the Creative Commons attribution share alike license (CC-BY-NC-SA; see http://creativecommons.org/licenses/by-nc-sa/4.0/). This means that you are allowed to copy and distribute these files freely, but you’re not allowed to sell them. It also means that if you create derivative works (i.e. if you remix, transform, or build upon the material), you must distribute your contributions under the same license as the original.

## Analyses

### Questionnaire

These data were gathered by the following hypothetical questionnaire:

```{r show-questionnaire}
questionnaire;
```

### Correlations between latent variables in the population

```{r latentAssociations}
associationMatrix(latentDat);
```

### Correlations in the sample (i.e. including measurement error)

```{r sampleAssociations}
associationMatrix(dat[, scaleNames]);
```

### Squared sample correlations

```{r squaredCorrelations}
cor(dat[, scaleNames]) ^ 2;
```

### Squared partial correlations

```{r squaredPartialCors}
pcor(dat[, scaleNames])$estimate ^ 2
```

### Squared semipartial correlations

```{r squaredSemiPartialCors}
spcor(dat[, scaleNames])$estimate ^ 2
```

### Visualisations of (explained) variances

This is the regression model without including importance.

```{r withoutExplicitOverlap}
grid.arrange(regsCovarPlot(intention ~ attitude + selfIdentity,
                           dat),
             regsCovarPlot(intention ~ attitude + selfIdentity,
                           dat, circle=TRUE),
             ncol=2);
```

Now we combine importance with attitude and with self-identity.

```{r withExplicitOverlap}
grid.arrange(regsCovarPlot(intention ~ attitudeImportance + selfIdentityImportance,
                           dat),
             regsCovarPlot(intention ~ attitudeImportance + selfIdentityImportance,
                           dat, circle=TRUE),
             ncol=2);
```

### The CIBER plots of these determinants

```{r CIBERplot-of-determinants, fig.width=11, fig.height=5, fig.cap="CIBER plots of both situations."}
grid.arrange(CIBER(dat, determinants=c('attitude', 'selfIdentity'), targets='intention'),
             CIBER(dat, determinants=c('attitudeImportance', 'selfIdentityImportance'), targets='intention'),
             ncol=1);
```

